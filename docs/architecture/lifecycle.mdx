import { FlowStep, Decision, Highlight } from "../../src/components/convengine";


# ðŸ”„ Conversation Lifecycle

This page walks through the **end-to-end lifecycle** of a conversation inside ConvEngine,
using the custom components to make each phase clear and visual.

---

## ðŸ§­ Lifecycle Overview

<FlowStep step="1" title="Conversation Bootstrap">
  A conversation is loaded from the database using <code>conversationId</code>.
  If it does not exist, a new one is created with default state <b>IDLE</b>.
</FlowStep>

<Decision type="deterministic">
  Conversation creation and lookup are purely database-driven.
</Decision>

---

<FlowStep step="2" title="Policy Enforcement">
  Blocking policies are evaluated before any intent or rule processing.
</FlowStep>

<Decision type="policy">
  If a policy matches, the conversation is immediately blocked.
</Decision>

---

<FlowStep step="3" title="Intent Classification">
  The engine classifies intent using <b>ce_intent_classifier</b> rules.
</FlowStep>

<Decision type="deterministic">
  Intent is resolved using regex / contains / starts-with rules.
</Decision>

---

<FlowStep step="4" title="Rule Processing">
  Rules from <b>ce_rule</b> are applied in priority order.
  Rules can update intent, update state, or short-circuit the flow.
</FlowStep>

---

<FlowStep step="5" title="Schema Completeness Check">
  If an output schema exists for the current intent + state,
  the engine validates the context JSON against it.
</FlowStep>

<Decision type="deterministic">
  Missing fields are detected without calling an LLM.
</Decision>

---

<FlowStep step="6" title="Response Resolution">
  Based on intent and state, the engine selects a response
  from <b>ce_response</b>.
</FlowStep>

<Decision type="llm">
  LLMs are used only if the response is DERIVED.
</Decision>

---

<FlowStep step="7" title="Persist & Return">
  Conversation state, context, and LLM logs are persisted.
  The final payload is returned to the client.
</FlowStep>

---

## ðŸ§  Key Takeaway

<Highlight type="golden-rule">
  The engine always decides first. The LLM only assists.
</Highlight>
